# ğŸ¦¥ Unsloth One-Shot Installer (Ubuntu 24.04 + Docker + RTX 2070 Super)

Dieses Repository enthÃ¤lt ein **vollautomatisches Bash-Skript**, das Unsloth samt CUDA 12.4, NVIDIA-Treiber, Docker, Conda, PyTorch 2.5.1 und Jupyter Lab in einem **One-Shot-Vorgang** installiert.

âœ… Kein manuelles Setup  
âœ… Kein CUDA-Raten  
âœ… Kein LLM-Frickeln  
âœ… Alles GPU-beschleunigt, sofort nutzbar

---

## ğŸ”§ Voraussetzungen

- Ubuntu **24.04 Server**
- **NVIDIA GPU** (z.â€¯B. RTX 2070 Super oder kompatibel mit CUDA 12.4)
- Internetverbindung
- Root-Zugriff (fÃ¼r `sudo`)

---

## ğŸš€ Schnellstart

```bash
git clone https://github.com/dominikwoh/TrainLLM.git
cd unsloth-oneshot
chmod +x install_unsloth_docker.sh
sudo ./install_unsloth_docker.sh
```

ğŸ“¦ Das Skript installiert automatisch:

- NVIDIA-Treiber **550**
- Docker & NVIDIA Container Toolkit
- `unsloth_env` Conda-Umgebung
- Jupyter Lab mit Token-Login
- Quant-ready Setup fÃ¼r GGUF-Export

---

## ğŸŒ Zugriff auf Jupyter Lab

Ã–ffne deinen Browser und rufe auf:

```
http://<DEINE_SERVER_IP>:8888
```

ğŸ” Login-Token: `12345678`

ğŸ“ Alle Notebooks liegen im Ordner `workspace/` (automatisch gemountet).

---

## ğŸ“„ Export als GGUF

Nach dem Training kannst du dein Modell direkt in GGUF exportieren:

```python
from unsloth import save_to_gguf

# LoRA + Base zusammenfÃ¼hren
model.save_pretrained_merged("merged", tokenizer, save_method="merged_16bit")

# Exportieren
save_to_gguf("merged", quantization_method="q4_k_m")
```

Ergebnis: `merged-q4_k_m.gguf` â†’ kompatibel mit llama.cpp, ollama, koboldcpp, etc.

---

## ğŸ” Container neu starten

```bash
cd ~/unsloth-docker
docker compose up -d
```

---

## ğŸ›¯ï¸ Container stoppen / entfernen

```bash
docker compose down
docker image rm unsloth-docker-unsloth
```

---

## ğŸ“ Lizenz

MIT â€“ feel free to fork & improve!


1. Server neustarten
FÃ¼hre einen sauberen Neustart durch, damit der neue Kernel und der NVIDIA-Treiber geladen werden:
Generated bash
sudo reboot
Use code with caution.
Bash
2. Nach dem Neustart: Treiber Ã¼berprÃ¼fen
Logge dich wieder ein und Ã¼berprÃ¼fe, ob der NVIDIA-Treiber jetzt korrekt lÃ¤uft. Gib diesen Befehl ein:
Generated bash
nvidia-smi
Use code with caution.
Bash
Wenn alles geklappt hat, solltest du eine Tabelle sehen, die deine RTX 2070 Super auflistet, zusammen mit der Treiberversion (sollte 550 sein) und dem CUDA-Level.
3. Container neu starten
Da der Treiber nun lÃ¤uft, kÃ¶nnen wir den Container, dessen Image bereits fertig gebaut wurde, einfach starten.
Generated bash
# Wechsle wieder in den Projektordner
cd /home/user/unsloth-docker/

# Starte den Container (diesmal wird es sehr schnell gehen)
docker compose up -d
Use code with caution.
Bash
Der Befehl docker compose up -d startet die in docker-compose.yml definierten Dienste im Hintergrund (-d fÃ¼r "detached").
Du kannst mit docker ps Ã¼berprÃ¼fen, ob der Container unsloth_jupyter jetzt lÃ¤uft.



## Im Jupyter Notebook Terminal:


```
# Installiert alle benÃ¶tigten System-Tools (cmake, libcurl)
!apt-get update && apt-get install -y cmake libcurl4-openssl-dev

# Klont llama.cpp (falls noch nicht vorhanden) und kompiliert es mit der neuen CMake-Methode
!git clone https://github.com/ggerganov/llama.cpp.git
!cd llama.cpp && rm -rf build && mkdir build && cd build && cmake .. && cmake --build .

print("\nâœ… Vorbereitung abgeschlossen. Llama.cpp ist jetzt kompiliert.")
```


